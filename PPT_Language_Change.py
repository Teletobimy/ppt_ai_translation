# translate_ppt.py  (ì„œì‹ ë³´ì¡´ + í†¤ ì„ íƒ ë²„ì „)
# pyinstaller --onefile --name BNK_TranslatePPT PPT_Language_Change.py
import os
import re
import time
import tkinter as tk
from tkinter import filedialog, messagebox
from pptx import Presentation
from pptx.dml.color import RGBColor
import openai


# ---------- [ì„œì‹ ë³´ì¡´ì„ ìœ„í•œ íƒœê¹…/ë³µì› ìœ í‹¸] ----------
RUN_TAG = re.compile(r"\[\[R(\d+)\]\]|\[\[/R(\d+)\]\]")
# ==== [ì„¤ì •] =====================================================
# ë§¨ ìœ„ import ê·¼ì²˜
SORRY_PATTERNS = [
    "i'm sorry", "i am sorry", "sorry, but", "apologize",
    "ì£„ì†¡í•˜ì§€ë§Œ", "ì£„ì†¡í•©ë‹ˆë‹¤", "ë²ˆì—­í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
]

def is_effectively_empty_tagged(tagged_text: str) -> bool:
    """[[R#]]ë§ˆì»¤ë¥¼ ì œê±°í•˜ê³  ë‚¨ëŠ” ì½˜í…ì¸ ê°€ ì‹¤ì§ˆì ìœ¼ë¡œ ë¹„ì—ˆëŠ”ì§€ íŒë‹¨"""
    stripped = RUN_TAG.sub("", tagged_text)  # ë§ˆì»¤ ì œê±°
    return stripped.strip() == ""  # ê³µë°±ë§Œ ë‚¨ìœ¼ë©´ ë¹ˆ ê²ƒìœ¼ë¡œ ê°„ì£¼

def looks_like_apology(text: str) -> bool:
    low = (text or "").lower()
    return any(p in low for p in SORRY_PATTERNS)



# API Keys - Use environment variables or Streamlit secrets
# For desktop app, set these as environment variables
# For Streamlit app, use st.secrets
EMBEDDED_OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")

LANG_OPTIONS = [
    "English",
    "Indonesian",
    "Italian",
    "French",
    "Spanish",
    "Korean",
    "Japanese",
    "Russian",
    "German",
    "Portuguese",
    "Chinese (Simplified)",
    "Chinese (Traditional)",
]

# âœ… í†¤ ì˜µì…˜ ì¶”ê°€
TONE_OPTIONS = [
    "ê¸°ë³¸ê°’",
    "Med/Pharma Pro (20y)",   # ì˜ë£Œê¸°ê¸°/ì „ë¬¸ì•½ì‚¬ 20ë…„ ì „ë¬¸ê°€
    "Beauty Pro (20y, chic)", # ì„¸ë ¨ëœ ë·°í‹° 20ë…„ ì „ë¬¸ê°€
    "GenZ Female (20s)",      # 20ëŒ€ ì—¬ì„± íƒ€ê¹ƒ
]

OPENAI_MODEL = "gpt-4o"
DEEPSEEK_MODEL = "deepseek-chat"
SLEEP_SEC = 0
# ===============================================================


def unique_path(path: str) -> str:  
    if not os.path.exists(path):
        return path
    base, ext = os.path.splitext(path)
    i = 1
    while True:
        candidate = f"{base} ({i}){ext}"
        if not os.path.exists(candidate):
            return candidate
        i += 1

def create_deepseek_client():
    """DeepSeek í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return openai.OpenAI(
        api_key=DEEPSEEK_API_KEY,
        base_url="https://api.deepseek.com"
    )


def safe_request(client, prompt, retries=3, delay=3, use_deepseek=False):
    for attempt in range(retries):
        try:
            model = DEEPSEEK_MODEL if use_deepseek else OPENAI_MODEL
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                timeout=60,
            )
            content = ""
            if resp and hasattr(resp, "choices") and resp.choices:
                content = getattr(resp.choices[0].message, "content", "") or ""
            if content:
                return content.strip()
        except Exception as e:
            print(f"âš ï¸ Error (attempt {attempt+1}): {e}")
            with open("error.log", "a", encoding="utf-8") as f:
                f.write(f"[Attempt {attempt+1}] {e}\n")
            time.sleep(delay)
    return ""




def _font_attrs(run):
    f = run.font
    # ê°’ ê·¸ëŒ€ë¡œ ë³´ì¡´(None í¬í•¨)
    name = f.name                 # Noneì´ë©´ í…Œë§ˆ/ë§ˆìŠ¤í„° ìƒì†
    size = f.size.pt if f.size else None
    bold = f.bold                 # True/False/None
    italic = f.italic             # True/False/None
    underline = f.underline       # True/False/None

    rgb = None
    if f.color is not None and getattr(f.color, "rgb", None) is not None:
        rgb = (f.color.rgb[0], f.color.rgb[1], f.color.rgb[2])

    return {"name": name, "size": size, "bold": bold, "italic": italic,
            "underline": underline, "rgb": rgb}

def _apply_font_attrs(run, attrs):
    from pptx.util import Pt
    f = run.font

    if attrs.get("name") is not None:
        f.name = attrs["name"]
    if attrs.get("size") is not None:
        f.size = Pt(attrs["size"])
    if attrs.get("bold") is not None:
        f.bold = attrs["bold"]
    if attrs.get("italic") is not None:
        f.italic = attrs["italic"]
    if attrs.get("underline") is not None:
        f.underline = attrs["underline"]
    if attrs.get("rgb") is not None:
        r, g, b = attrs["rgb"]
        f.color.rgb = RGBColor(r, g, b)


def tag_paragraph(paragraph):
    text_parts, style_map, idx = [], {}, 1
    for run in paragraph.runs:
        t = run.text or ""
        if not t:
            continue
        style_map[idx] = _font_attrs(run)
        text_parts.append(f"[[R{idx}]]{t}[[/R{idx}]]")
        idx += 1
    return "".join(text_parts), style_map

def rebuild_paragraph_from_tagged(paragraph, translated, style_map):
    while paragraph.runs:
        paragraph.runs[0]._r.getparent().remove(paragraph.runs[0]._r)

    tokens, pos = [], 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            tokens.append(("text", translated[pos:s]))
        if m.group(1):
            tokens.append(("start", int(m.group(1))))
        if m.group(2):
            tokens.append(("end", int(m.group(2))))
        pos = e
    if pos < len(translated):
        tokens.append(("text", translated[pos:]))

    out_runs, stack, buffer = [], [], {}
    for ttype, value in tokens:
        if ttype == "start":
            stack.append(value)
            buffer.setdefault(value, [])
        elif ttype == "end":
            if stack and stack[-1] == value:
                stack.pop()
            joined = "".join(buffer.get(value, []))
            out_runs.append((value, joined))
            buffer[value] = []
        else:
            if stack:
                buffer[stack[-1]].append(value)
            else:
                out_runs.append((None, value))

    for run_id, buf in buffer.items():
        if buf:
            out_runs.append((run_id, "".join(buf)))

    if not out_runs:
        r = paragraph.add_run()
        r.text = translated
        return

    for run_id, txt in out_runs:
        if not txt:
            continue
        r = paragraph.add_run()
        r.text = txt
        if run_id and run_id in style_map:
            _apply_font_attrs(r, style_map[run_id])

def _parse_run_chunks(translated):
    # R# â†’ í…ìŠ¤íŠ¸ ë§¤í•‘ê³¼, ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€ë¥¼ íŒì •
    ids = []
    chunks = {}
    stack = []
    buf = {}
    outside = []

    pos = 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            if stack:
                buf.setdefault(stack[-1], []).append(translated[pos:s])
            else:
                outside.append(translated[pos:s])
        if m.group(1):  # [[R#]]
            rid = int(m.group(1)); stack.append(rid); ids.append(rid)
        if m.group(2):  # [[/R#]]
            rid = int(m.group(2))
            if stack and stack[-1] == rid:
                stack.pop()
                joined = "".join(buf.get(rid, []))
                chunks[rid] = joined
                buf[rid] = []
        pos = e
    if pos < len(translated):
        if stack:
            buf.setdefault(stack[-1], []).append(translated[pos:])
        else:
            outside.append(translated[pos:])

    # ë‹«íˆì§€ ì•Šì€ ë²„í¼ ì²˜ë¦¬
    for rid, lst in buf.items():
        if lst:
            chunks[rid] = chunks.get(rid, "") + "".join(lst)

    has_outside = any(t.strip() for t in outside)
    return ids, chunks, has_outside

def try_inplace_update_paragraph(paragraph, translated):
    """ë§ˆì»¤ê°€ 1..Nìœ¼ë¡œ ì •í™•íˆ ì¡´ì¬í•˜ê³ , ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´
    ê¸°ì¡´ runsì— í…ìŠ¤íŠ¸ë§Œ ì£¼ì…í•˜ì—¬ ì„œì‹ì„ 100% ìœ ì§€í•œë‹¤."""
    ids, chunks, has_outside = _parse_run_chunks(translated)
    runs = [r for r in paragraph.runs if (r.text or "") != ""]
    N = len(runs)

    # ì¡°ê±´: ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ê°€ ì—†ì–´ì•¼ í•˜ê³ , R1..RNì´ ì •í™•íˆ í•œ ë²ˆì”© ì¡´ì¬
    if has_outside or N == 0 or set(ids) != set(range(1, N+1)) or any(ids.count(i) != 1 for i in range(1, N+1)):
        return False

    for i, run in enumerate(runs, start=1):
        run.text = chunks.get(i, "")
    return True


# ---------- [í”„ë¡¬í”„íŠ¸ ë¹Œë”] ----------
def build_tone_instructions(tone: str) -> str:
    """
    ì„ íƒí•œ í†¤ì— ë§ëŠ” ì§€ì‹œë¬¸ì„ ë°˜í™˜
    """
    if tone == "ê¸°ë³¸ê°’":
        return (
            "Use a natural, professional beauty-industry tone localized to the target market. "
            "Keep terminology consistent with beauty marketing and professional skincare. "
            "Be clear and persuasive without hype; avoid overpromising."
        )
    if tone == "Med/Pharma Pro (20y)":
        return (
            "Use a formal, clinically precise B2B tone suitable for medical devices and professional pharmacists. "
            "Prioritize clarity, compliance, and evidence-based wording. Avoid hype. "
            "Prefer terminology used in regulatory, clinical, and professional settings."
        )
    if tone == "Beauty Pro (20y, chic)":
        return (
            "Use a refined, polished professional tone common in premium beauty and aesthetic clinics. "
            "Balance expertise with approachable elegance. Maintain brand voice consistency without overpromising."
        )
    if tone == "GenZ Female (20s)":
        return (
            "Use a modern, friendly, and concise tone tailored for women in their 20s. "
            "Be clear and engaging for social content, but avoid slang overload, emojis, and exaggerated claims."
        )
    # fallback
    return "Use a neutral professional tone appropriate for the beauty industry."

def build_chinese_prompt(tagged_text: str, target_lang: str) -> str:
    """
    ì „ë¬¸ì ì¸ í•œêµ­ì–´â†’ì¤‘êµ­ì–´ ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (ê°„ì²´/ë²ˆì²´ êµ¬ë¶„)
    """
    chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
    
    return (
        f"ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì¤‘êµ­ì–´({chinese_type})ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
        f"# ì£¼ìš” íŠ¹ì§•\n"
        f"- í”„ë ˆì  í…Œì´ì…˜, ë³´ê³ ì„œ, ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ ë“±ì— ì í•©í•œ ê³µì‹ì ì´ê³  ì„¸ë ¨ëœ í‘œí˜„ ì‚¬ìš©\n"
        f"- ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ì™€ ë‰˜ì•™ìŠ¤ë¥¼ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í‘œí˜„ìœ¼ë¡œ ë²ˆì—­\n"
        f"- ì›ë¬¸ì˜ ì˜ë„ì™€ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë˜, ì¤‘êµ­ ì›ì–´ë¯¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ë¦¬ë„ë¡ ë¬¸ì¥ êµ¬ì¡° ì¡°ì •\n"
        f"- ë²ˆì—­ ì´ì™¸ì˜ ë¶ˆí•„ìš”í•œ ì„¤ëª… ê¸ˆì§€\n"
        f"- ì°½ì˜ì  ì¬í•´ì„ ì—†ì´ ì›ë¬¸ì— ì¶©ì‹¤í•œ ë²ˆì—­ ìˆ˜í–‰\n"
        f"- ë°˜ë“œì‹œ ì¤‘êµ­ì–´ {chinese_type}ë¡œ ë²ˆì—­í•˜ì„¸ìš”\n\n"
        f"# ê³ ìœ ëª…ì‚¬ ì²˜ë¦¬ ê·œì¹™\n"
        f"- 'í”¼ë”ë¦°'ì€ 'PYDERIN'ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš” (ë¸Œëœë“œëª…ì´ë¯€ë¡œ ëŒ€ë¬¸ìë¡œ)\n"
        f"- ê¸°íƒ€ ê³ ìœ ëª…ì‚¬(ì¸ëª…, ì§€ëª…, íšŒì‚¬ëª…, ë¸Œëœë“œëª… ë“±)ëŠ” ë²ˆì—­í•˜ì§€ ë§ê³  ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”\n"
        f"- ì˜ì–´ ê³ ìœ ëª…ì‚¬ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”\n\n"
        f"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì¤‘êµ­ì–´({chinese_type})ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\n"
        f"ì¤‘ìš”: [[R1]]...[[/R1]] ê°™ì€ ë§ˆì»¤ íƒœê·¸ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ê±°ë‚˜ ì œê±°í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        f"ë²ˆì—­í•  í…ìŠ¤íŠ¸:\n{tagged_text}"
    )

def build_prompt(tagged_text: str, target_lang: str, tone: str) -> str:
    # Chinese translation uses specialized prompt
    if "Chinese" in target_lang:
        return build_chinese_prompt(tagged_text, target_lang)
    
    tone_text = build_tone_instructions(tone)
    return (
        f"Translate the following beauty industry presentation text into natural, professional {target_lang}. "
        f"Only return the translated text. If there is nothing to translate, return an empty string. "
        f"Context: {tone_text} "
        f"Avoid literal translationâ€”use expressions that sound natural for beauty marketing and professional skincare. "
        f"If the source is already in {target_lang}, lightly copyedit for clarity, consistency, and terminology. "
        f"CRITICAL: Do NOT alter or remove any marker tags like [[R1]]...[[/R1]]. Keep them exactly as-is and in correct pairs. "
        f"Return the translated text with all markers preserved:\n\n{tagged_text}"
    )



# ---------- [ë²ˆì—­ í˜¸ì¶œ] ----------
def gpt_translate_tagged(tagged_text: str, client, target_lang: str, tone: str, use_deepseek=False) -> str:
    # ì§„ì§œ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ë²ˆì—­ ìŠ¤í‚µ
    if not tagged_text.strip() or is_effectively_empty_tagged(tagged_text):
        return ""

    # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° DeepSeek ì‚¬ìš©
    if "Chinese" in target_lang and use_deepseek:
        deepseek_client = create_deepseek_client()
        prompt = build_chinese_prompt(tagged_text, target_lang)
        content = safe_request(deepseek_client, prompt, retries=3, delay=3, use_deepseek=True)
    else:
        prompt = build_prompt(tagged_text, target_lang, tone)
        content = safe_request(client, prompt, retries=3, delay=3)

    # ì‹¤íŒ¨ ì‹œ ì›ë¬¸(ë§ˆì»¤ í¬í•¨) ë°˜í™˜ â†’ ì›ë¬¸ ìœ ì§€
    if not content:
        return tagged_text

    # ì‚¬ê³¼ë¬¸/ì—ëŸ¬ë¬¸êµ¬ê°€ ë“¤ì–´ì˜¤ë©´ ì›ë¬¸ ìœ ì§€
    if looks_like_apology(content):
        return tagged_text

    return content

def gpt_review_chinese_translation(original_korean: str, translated_chinese: str, client, use_deepseek=False) -> dict:
    """
    ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ìì—°ìŠ¤ëŸ¬ì›€ì„ ê²€í† í•˜ê³  í•„ìš”ì‹œ ìˆ˜ì •ëœ ë²ˆì—­ì„ ë°˜í™˜
    """
    if not original_korean.strip() or not translated_chinese.strip():
        return {"is_awkward": False, "revised_translation": translated_chinese}
    
    review_prompt = (
        f"ë‹¹ì‹ ì€ ì¤‘êµ­ì–´ ë²ˆì—­ í’ˆì§ˆì„ ê²€í† í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
        f"ì›ë¬¸ (í•œêµ­ì–´): {original_korean}\n"
        f"ë²ˆì—­ë¬¸ (ì¤‘êµ­ì–´): {translated_chinese}\n\n"
        f"ë‹¤ìŒì„ ê²€í† í•´ì£¼ì„¸ìš”:\n"
        f"1. ì¤‘êµ­ ì›ì–´ë¯¼ì´ ì½ì—ˆì„ ë•Œ ì–´ìƒ‰í•˜ê±°ë‚˜ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¶€ë¶„ì´ ìˆëŠ”ê°€?\n"
        f"2. ë¬¸ë²•ì ìœ¼ë¡œ ì˜¬ë°”ë¥¸ê°€?\n"
        f"3. í‘œí˜„ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?\n\n"
        f"ì‘ë‹µ í˜•ì‹:\n"
        f"ì–´ìƒ‰í•¨: [YES/NO]\n"
        f"ìˆ˜ì •ëœ ë²ˆì—­: [ìˆ˜ì •ëœ ì¤‘êµ­ì–´ ë²ˆì—­ ë˜ëŠ” ì›ë˜ ë²ˆì—­]\n"
        f"ì„¤ëª…: [ì–´ìƒ‰í•œ ì´ìœ  ë˜ëŠ” ìˆ˜ì • ì‚¬í•­]\n\n"
        f"ì¤‘ìš”: [[R1]]...[[/R1]] ê°™ì€ ë§ˆì»¤ íƒœê·¸ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”."
    )
    
    try:
        if use_deepseek:
            deepseek_client = create_deepseek_client()
            content = safe_request(deepseek_client, review_prompt, retries=2, delay=2, use_deepseek=True)
        else:
            content = safe_request(client, review_prompt, retries=2, delay=2)
            
        if not content:
            return {"is_awkward": False, "revised_translation": translated_chinese}
        
        # Parse response
        lines = content.strip().split('\n')
        is_awkward = False
        revised_translation = translated_chinese
        
        for line in lines:
            if line.startswith("ì–´ìƒ‰í•¨:"):
                is_awkward = "YES" in line.upper()
            elif line.startswith("ìˆ˜ì •ëœ ë²ˆì—­:"):
                revised_translation = line.replace("ìˆ˜ì •ëœ ë²ˆì—­:", "").strip()
        
        return {"is_awkward": is_awkward, "revised_translation": revised_translation}
        
    except Exception as e:
        print(f"âš ï¸ Review error: {e}")
        return {"is_awkward": False, "revised_translation": translated_chinese}




# ---------- [íŒŒì¼/ì–¸ì–´/í†¤ ì„ íƒ UI] ----------
def choose_pptx_with_dialog() -> str:
    root = tk.Tk()
    root.withdraw()
    root.update_idletasks()
    filepath = filedialog.askopenfilename(
        title="ë²ˆì—­í•  PPTX íŒŒì¼ ì„ íƒ",
        filetypes=[("PowerPoint files", "*.pptx")],
    )
    root.destroy()
    return filepath or ""

def choose_language_with_window() -> str:
    sel = {"value": ""}

    def on_start():
        v = var.get().strip()
        if not v:
            messagebox.showwarning("ì•Œë¦¼", "ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            return
        sel["value"] = v
        win.destroy()

    win = tk.Tk()
    win.title("Target Language")
    win.geometry("360x160")
    win.resizable(False, False)

    frm = tk.Frame(win, padx=12, pady=12)
    frm.pack(fill="both", expand=True)

    tk.Label(frm, text="ë²ˆì—­ ëŒ€ìƒ ì–¸ì–´ ì„ íƒ:").pack(anchor="w", pady=(0, 6))

    var = tk.StringVar(value=LANG_OPTIONS[0])
    opt = tk.OptionMenu(frm, var, *LANG_OPTIONS)
    opt.pack(fill="x")

    tk.Button(frm, text="ë‹¤ìŒ(í†¤ ì„ íƒ)", command=on_start).pack(pady=12)

    win.lift(); win.attributes("-topmost", True); win.after(200, lambda: win.attributes("-topmost", False))
    win.mainloop()
    return sel["value"]

def choose_tone_with_window(selected_language: str) -> tuple:
    sel = {"value": "", "use_deepseek": False}

    def on_start():
        v = var.get().strip()
        if not v:
            messagebox.showwarning("ì•Œë¦¼", "í†¤ì„ ì„ íƒí•˜ì„¸ìš”.")
            return
        sel["value"] = v
        sel["use_deepseek"] = deepseek_var.get()
        win.destroy()

    win = tk.Tk()
    win.title("Target Tone & DeepSeek Option")
    win.geometry("450x280")
    win.resizable(False, False)

    frm = tk.Frame(win, padx=12, pady=12)
    frm.pack(fill="both", expand=True)

    tk.Label(frm, text="ë²ˆì—­ í†¤ ì„ íƒ:").pack(anchor="w", pady=(0, 6))

    var = tk.StringVar(value=TONE_OPTIONS[0])
    opt = tk.OptionMenu(frm, var, *TONE_OPTIONS)
    opt.pack(fill="x")

    # DeepSeek ì‚¬ìš© ì˜µì…˜ (ì¤‘êµ­ì–´ì¼ ë•Œë§Œ í‘œì‹œ)
    if "Chinese" in selected_language:
        deepseek_frame = tk.Frame(frm)
        deepseek_frame.pack(fill="x", pady=(10, 0))
        
        deepseek_var = tk.BooleanVar(value=True)
        chinese_type = "ê°„ì²´" if "Simplified" in selected_language else "ë²ˆì²´"
        deepseek_check = tk.Checkbutton(
            deepseek_frame,
            text=f"ì¤‘êµ­ì–´({chinese_type}) ë²ˆì—­ ì‹œ DeepSeek ì‚¬ìš© (ê¶Œì¥)",
            variable=deepseek_var,
            font=("Arial", 9, "bold")
        )
        deepseek_check.pack(anchor="w")
        
        deepseek_info = tk.Label(
            deepseek_frame,
            text=f"âœ“ DeepSeekì€ ì¤‘êµ­ì–´({chinese_type}) ë²ˆì—­ì— íŠ¹í™”ë˜ì–´ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤",
            font=("Arial", 8),
            fg="blue"
        )
        deepseek_info.pack(anchor="w", pady=(2, 0))
    else:
        deepseek_var = tk.BooleanVar(value=False)

    # ê°„ë‹¨í•œ ì„¤ëª… ë¼ë²¨
    info = tk.Label(
        frm,
        justify="left",
        text=(
            "- ê¸°ë³¸ê°’: ì¼ë°˜ë·°í‹°ì—…ê³„, ì§ì—­ ìµœëŒ€í•œ íšŒí”¼\n"
            "- Med/Pharma Pro: ì˜ë£Œê¸°ê¸°/ì „ë¬¸ì•½ì‚¬ 20ë…„ ì „ë¬¸ê°€ í†¤\n"
            "- Beauty Pro (chic): í”„ë¦¬ë¯¸ì—„ ë·°í‹° ì „ë¬¸ê°€ í†¤\n"
            "- GenZ Female: 20ëŒ€ ì—¬ì„± íƒ€ê¹ƒì˜ ì¹œê·¼í•œ í†¤(ê³¼ì¥Â·ìŠ¬ë­ ê³¼ë‹¤ ê¸ˆì§€)"
        ),
    )
    info.pack(anchor="w", pady=8)

    tk.Button(frm, text="ë²ˆì—­ ì‹œì‘", command=on_start).pack(pady=6)

    win.lift(); win.attributes("-topmost", True); win.after(200, lambda: win.attributes("-topmost", False))
    win.mainloop()
    return sel["value"], sel["use_deepseek"]


# ---------- [ë³¸ ì²˜ë¦¬] ----------
def translate_presentation(pptx_path: str, target_lang: str, tone: str, use_deepseek=False):
    print(f"ğŸ“‚ íŒŒì¼: {pptx_path}")
    print(f"ğŸŒ ëŒ€ìƒ ì–¸ì–´: {target_lang}")
    print(f"ğŸ™ í†¤: {tone}")
    if target_lang == "Chinese" and use_deepseek:
        print("ğŸ¤– DeepSeek ëª¨ë¸ ì‚¬ìš© ì¤‘...")
    else:
        print("ğŸ”‘ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")

    client = openai.OpenAI(api_key=EMBEDDED_OPENAI_API_KEY)

    print("ğŸ“– í”„ë ˆì  í…Œì´ì…˜ ë¡œë”©...")
    pres = Presentation(pptx_path)

    slide_count = len(pres.slides)
    print(f"ğŸ–¼ ìŠ¬ë¼ì´ë“œ ìˆ˜: {slide_count}")
    
    # ì›ë³¸ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°±ì—… (ì¤‘êµ­ì–´ ë²ˆì—­ìš©)
    original_korean_backup = {}
    if "Chinese" in target_lang:
        chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
        print(f"ğŸ“ ì›ë³¸ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°±ì—… ì¤‘... (ì¤‘êµ­ì–´ {chinese_type} ë²ˆì—­ìš©)")
        for s_idx, slide in enumerate(pres.slides, start=1):
            original_korean_backup[s_idx] = {}
            for shape_idx, shape in enumerate(slide.shapes):
                if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
                    tf = shape.text_frame
                    for p_idx, p in enumerate(tf.paragraphs):
                        tagged, _ = tag_paragraph(p)
                        if tagged:
                            original_korean_backup[s_idx][f"{shape_idx}_{p_idx}"] = tagged
                elif getattr(shape, "has_table", False) and shape.has_table:
                    for row_idx, row in enumerate(shape.table.rows):
                        for cell_idx, cell in enumerate(row.cells):
                            if not getattr(cell, "text_frame", None):
                                continue
                            tf = cell.text_frame
                            for p_idx, p in enumerate(tf.paragraphs):
                                tagged, _ = tag_paragraph(p)
                                if tagged:
                                    original_korean_backup[s_idx][f"table_{row_idx}_{cell_idx}_{p_idx}"] = tagged
    
    print("-" * 60)

    for s_idx, slide in enumerate(pres.slides, start=1):
        print(f"â–¶ ìŠ¬ë¼ì´ë“œ {s_idx}/{slide_count}")

        for shape_idx, shape in enumerate(slide.shapes):
            # í…ìŠ¤íŠ¸ í”„ë ˆì„
            if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
                tf = shape.text_frame
                for p_idx, p in enumerate(tf.paragraphs):
                    tagged, style_map = tag_paragraph(p)
                    if not tagged:
                        continue
                    preview = (tagged[:40] + "...") if len(tagged) > 40 else tagged
                    print(f"   ğŸ”¤ ë²ˆì—­ ì¤‘(ì„œì‹ë³´ì¡´): {preview}")
                    translated = gpt_translate_tagged(tagged, client, target_lang, tone, use_deepseek)
                    translated = translated.strip().strip('"').strip("'")
                    
                    # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° ê²€í†  ë° ìˆ˜ì •
                    if "Chinese" in target_lang:
                        original_korean = original_korean_backup.get(s_idx, {}).get(f"{shape_idx}_{p_idx}", tagged)
                        review_result = gpt_review_chinese_translation(original_korean, translated, client, use_deepseek)
                        if review_result["is_awkward"]:
                            translated = review_result["revised_translation"]
                            chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
                            print(f"   âœ… ì–´ìƒ‰í•œ ë²ˆì—­ ê°ì§€ (ì¤‘êµ­ì–´ {chinese_type}) - ìˆ˜ì •ë¨")
                    
                    if not try_inplace_update_paragraph(p, translated):
                      # 2ï¸âƒ£ ì‹¤íŒ¨í•˜ë©´ rebuild ë°©ì‹ìœ¼ë¡œ fallback
                       rebuild_paragraph_from_tagged(p, translated, style_map)
                    
                    time.sleep(SLEEP_SEC)

            # í‘œ(ì…€ ë‚´ë¶€ë„ paragraph ë‹¨ìœ„ë¡œ ì²˜ë¦¬)
            elif getattr(shape, "has_table", False) and shape.has_table:
                for row_idx, row in enumerate(shape.table.rows):
                    for cell_idx, cell in enumerate(row.cells):
                        if not getattr(cell, "text_frame", None):
                            continue
                        tf = cell.text_frame
                        for p_idx, p in enumerate(tf.paragraphs):
                            tagged, style_map = tag_paragraph(p)
                            if not tagged:
                                continue
                            translated = gpt_translate_tagged(tagged, client, target_lang, tone, use_deepseek)
                            translated = translated.strip().strip('"').strip("'")
                            
                            # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° ê²€í†  ë° ìˆ˜ì •
                            if "Chinese" in target_lang:
                                original_korean = original_korean_backup.get(s_idx, {}).get(f"table_{row_idx}_{cell_idx}_{p_idx}", tagged)
                                review_result = gpt_review_chinese_translation(original_korean, translated, client, use_deepseek)
                                if review_result["is_awkward"]:
                                    translated = review_result["revised_translation"]
                                    chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
                                    print(f"   âœ… ì–´ìƒ‰í•œ ë²ˆì—­ ê°ì§€ (í‘œ, ì¤‘êµ­ì–´ {chinese_type}) - ìˆ˜ì •ë¨")
                            
                            if not try_inplace_update_paragraph(p, translated):
                                rebuild_paragraph_from_tagged(p, translated, style_map)
                            time.sleep(SLEEP_SEC)

    folder = os.path.dirname(pptx_path)
    stem, ext = os.path.splitext(os.path.basename(pptx_path))
    
    # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° í†¤ ëŒ€ì‹  ì¤‘êµ­ì–´ íƒ€ì…ì„ ì‚¬ìš©
    if "Chinese" in target_lang:
        chinese_type = "Simplified" if "Simplified" in target_lang else "Traditional"
        outfile_name = f"{stem}_Chinese_{chinese_type}_AIë²ˆì—­ì™„ë£Œ{ext}"
    else:
        safe_tone = re.sub(r'[^0-9A-Za-zê°€-í£_()+-]', '', tone.replace(' ', ''))
        outfile_name = f"{stem}_{target_lang}_{safe_tone}_AIë²ˆì—­ì™„ë£Œ{ext}"
    
    outfile_path = os.path.join(folder, outfile_name)
    outfile_path = unique_path(outfile_path)

    print("-" * 60)
    print("ğŸ’¾ ì €ì¥ ì¤‘...")
    pres.save(outfile_path)
    print(f"âœ… ë²ˆì—­ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {outfile_path}")


def main():
    pptx_path = choose_pptx_with_dialog()
    if not pptx_path:
        print("âŒ íŒŒì¼ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    target_lang = choose_language_with_window()
    if not target_lang:
        print("âŒ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    tone, use_deepseek = choose_tone_with_window(target_lang)
    if not tone:
        print("âŒ í†¤ì„ ì„ íƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    translate_presentation(pptx_path, target_lang, tone, use_deepseek)


if __name__ == "__main__":
    main()
