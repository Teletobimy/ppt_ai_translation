# translation_engine.py
# Core translation logic extracted from PPT_Language_Change.py

import os
import re
import time
from pptx import Presentation
from pptx.dml.color import RGBColor
import openai


# ---------- [ì„œì‹ ë³´ì¡´ì„ ìœ„í•œ íƒœê¹…/ë³µì› ìœ í‹¸] ----------
RUN_TAG = re.compile(r"\[\[R(\d+)\]\]|\[\[/R(\d+)\]\]")

# ==== [ì„¤ì •] =====================================================
SORRY_PATTERNS = [
    "i'm sorry", "i am sorry", "sorry, but", "apologize",
    "ì£„ì†¡í•˜ì§€ë§Œ", "ì£„ì†¡í•©ë‹ˆë‹¤", "ë²ˆì—­í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"
]

LANG_OPTIONS = [
    "English",
    "Indonesian",
    "Italian",
    "French",
    "Spanish",
    "Korean",
    "Japanese",
    "Russian",
    "German",
    "Portuguese",
    "Chinese (Simplified)",
    "Chinese (Traditional)",
]

TONE_OPTIONS = [
    "ê¸°ë³¸ê°’",
    "Med/Pharma Pro (20y)",   # ì˜ë£Œê¸°ê¸°/ì „ë¬¸ì•½ì‚¬ 20ë…„ ì „ë¬¸ê°€
    "Beauty Pro (20y, chic)", # ì„¸ë ¨ëœ ë·°í‹° 20ë…„ ì „ë¬¸ê°€
    "GenZ Female (20s)",      # 20ëŒ€ ì—¬ì„± íƒ€ê¹ƒ
]

OPENAI_MODEL = "gpt-4o"
DEEPSEEK_MODEL = "deepseek-chat"
SLEEP_SEC = 0


def is_effectively_empty_tagged(tagged_text: str) -> bool:
    """[[R#]]ë§ˆì»¤ë¥¼ ì œê±°í•˜ê³  ë‚¨ëŠ” ì½˜í…ì¸ ê°€ ì‹¤ì§ˆì ìœ¼ë¡œ ë¹„ì—ˆëŠ”ì§€ íŒë‹¨"""
    stripped = RUN_TAG.sub("", tagged_text)  # ë§ˆì»¤ ì œê±°
    return stripped.strip() == ""  # ê³µë°±ë§Œ ë‚¨ìœ¼ë©´ ë¹ˆ ê²ƒìœ¼ë¡œ ê°„ì£¼


def looks_like_apology(text: str) -> bool:
    low = (text or "").lower()
    return any(p in low for p in SORRY_PATTERNS)


def unique_path(path: str) -> str:  
    if not os.path.exists(path):
        return path
    base, ext = os.path.splitext(path)
    i = 1
    while True:
        candidate = f"{base} ({i}){ext}"
        if not os.path.exists(candidate):
            return candidate
        i += 1


def create_openai_client(api_key: str):
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return openai.OpenAI(api_key=api_key)


def create_deepseek_client(api_key: str):
    """DeepSeek í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    return openai.OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com"
    )


def safe_request(client, prompt, retries=3, delay=3, use_deepseek=False):
    for attempt in range(retries):
        try:
            model = DEEPSEEK_MODEL if use_deepseek else OPENAI_MODEL
            resp = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                timeout=60,
            )
            content = ""
            if resp and hasattr(resp, "choices") and resp.choices:
                content = getattr(resp.choices[0].message, "content", "") or ""
            if content:
                return content.strip()
        except Exception as e:
            print(f"âš ï¸ Error (attempt {attempt+1}): {e}")
            with open("error.log", "a", encoding="utf-8") as f:
                f.write(f"[Attempt {attempt+1}] {e}\n")
            time.sleep(delay)
    return ""


def _font_attrs(run):
    f = run.font
    # ê°’ ê·¸ëŒ€ë¡œ ë³´ì¡´(None í¬í•¨)
    name = f.name                 # Noneì´ë©´ í…Œë§ˆ/ë§ˆìŠ¤í„° ìƒì†
    size = f.size.pt if f.size else None
    bold = f.bold                 # True/False/None
    italic = f.italic             # True/False/None
    underline = f.underline       # True/False/None

    rgb = None
    if f.color is not None and getattr(f.color, "rgb", None) is not None:
        rgb = (f.color.rgb[0], f.color.rgb[1], f.color.rgb[2])

    return {"name": name, "size": size, "bold": bold, "italic": italic,
            "underline": underline, "rgb": rgb}


def _apply_font_attrs(run, attrs):
    from pptx.util import Pt
    f = run.font

    if attrs.get("name") is not None:
        f.name = attrs["name"]
    if attrs.get("size") is not None:
        f.size = Pt(attrs["size"])
    if attrs.get("bold") is not None:
        f.bold = attrs["bold"]
    if attrs.get("italic") is not None:
        f.italic = attrs["italic"]
    if attrs.get("underline") is not None:
        f.underline = attrs["underline"]
    if attrs.get("rgb") is not None:
        r, g, b = attrs["rgb"]
        f.color.rgb = RGBColor(r, g, b)


def tag_paragraph(paragraph):
    text_parts, style_map, idx = [], {}, 1
    for run in paragraph.runs:
        t = run.text or ""
        if not t:
            continue
        style_map[idx] = _font_attrs(run)
        text_parts.append(f"[[R{idx}]]{t}[[/R{idx}]]")
        idx += 1
    return "".join(text_parts), style_map


def rebuild_paragraph_from_tagged(paragraph, translated, style_map):
    while paragraph.runs:
        paragraph.runs[0]._r.getparent().remove(paragraph.runs[0]._r)

    tokens, pos = [], 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            tokens.append(("text", translated[pos:s]))
        if m.group(1):
            tokens.append(("start", int(m.group(1))))
        if m.group(2):
            tokens.append(("end", int(m.group(2))))
        pos = e
    if pos < len(translated):
        tokens.append(("text", translated[pos:]))

    out_runs, stack, buffer = [], [], {}
    for ttype, value in tokens:
        if ttype == "start":
            stack.append(value)
            buffer.setdefault(value, [])
        elif ttype == "end":
            if stack and stack[-1] == value:
                stack.pop()
            joined = "".join(buffer.get(value, []))
            out_runs.append((value, joined))
            buffer[value] = []
        else:
            if stack:
                buffer[stack[-1]].append(value)
            else:
                out_runs.append((None, value))

    for run_id, buf in buffer.items():
        if buf:
            out_runs.append((run_id, "".join(buf)))

    if not out_runs:
        r = paragraph.add_run()
        r.text = translated
        return

    for run_id, txt in out_runs:
        if not txt:
            continue
        r = paragraph.add_run()
        r.text = txt
        if run_id and run_id in style_map:
            _apply_font_attrs(r, style_map[run_id])


def _parse_run_chunks(translated):
    # R# â†’ í…ìŠ¤íŠ¸ ë§¤í•‘ê³¼, ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€ë¥¼ íŒì •
    ids = []
    chunks = {}
    stack = []
    buf = {}
    outside = []

    pos = 0
    for m in RUN_TAG.finditer(translated):
        s, e = m.span()
        if s > pos:
            if stack:
                buf.setdefault(stack[-1], []).append(translated[pos:s])
            else:
                outside.append(translated[pos:s])
        if m.group(1):  # [[R#]]
            rid = int(m.group(1)); stack.append(rid); ids.append(rid)
        if m.group(2):  # [[/R#]]
            rid = int(m.group(2))
            if stack and stack[-1] == rid:
                stack.pop()
                joined = "".join(buf.get(rid, []))
                chunks[rid] = joined
                buf[rid] = []
        pos = e
    if pos < len(translated):
        if stack:
            buf.setdefault(stack[-1], []).append(translated[pos:])
        else:
            outside.append(translated[pos:])

    # ë‹«íˆì§€ ì•Šì€ ë²„í¼ ì²˜ë¦¬
    for rid, lst in buf.items():
        if lst:
            chunks[rid] = chunks.get(rid, "") + "".join(lst)

    has_outside = any(t.strip() for t in outside)
    return ids, chunks, has_outside


def try_inplace_update_paragraph(paragraph, translated):
    """ë§ˆì»¤ê°€ 1..Nìœ¼ë¡œ ì •í™•íˆ ì¡´ì¬í•˜ê³ , ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´
    ê¸°ì¡´ runsì— í…ìŠ¤íŠ¸ë§Œ ì£¼ì…í•˜ì—¬ ì„œì‹ì„ 100% ìœ ì§€í•œë‹¤."""
    ids, chunks, has_outside = _parse_run_chunks(translated)
    runs = [r for r in paragraph.runs if (r.text or "") != ""]
    N = len(runs)

    # ì¡°ê±´: ë§ˆì»¤ ë°– í…ìŠ¤íŠ¸ê°€ ì—†ì–´ì•¼ í•˜ê³ , R1..RNì´ ì •í™•íˆ í•œ ë²ˆì”© ì¡´ì¬
    if has_outside or N == 0 or set(ids) != set(range(1, N+1)) or any(ids.count(i) != 1 for i in range(1, N+1)):
        return False

    for i, run in enumerate(runs, start=1):
        run.text = chunks.get(i, "")
    return True


# ---------- [í”„ë¡¬í”„íŠ¸ ë¹Œë”] ----------
def build_tone_instructions(tone: str) -> str:
    """
    ì„ íƒí•œ í†¤ì— ë§ëŠ” ì§€ì‹œë¬¸ì„ ë°˜í™˜
    """
    if tone == "ê¸°ë³¸ê°’":
        return (
            "Use a natural, professional beauty-industry tone localized to the target market. "
            "Keep terminology consistent with beauty marketing and professional skincare. "
            "Be clear and persuasive without hype; avoid overpromising."
        )
    if tone == "Med/Pharma Pro (20y)":
        return (
            "Use a formal, clinically precise B2B tone suitable for medical devices and professional pharmacists. "
            "Prioritize clarity, compliance, and evidence-based wording. Avoid hype. "
            "Prefer terminology used in regulatory, clinical, and professional settings."
        )
    if tone == "Beauty Pro (20y, chic)":
        return (
            "Use a refined, polished professional tone common in premium beauty and aesthetic clinics. "
            "Balance expertise with approachable elegance. Maintain brand voice consistency without overpromising."
        )
    if tone == "GenZ Female (20s)":
        return (
            "Use a modern, friendly, and concise tone tailored for women in their 20s. "
            "Be clear and engaging for social content, but avoid slang overload, emojis, and exaggerated claims."
        )
    # fallback
    return "Use a neutral professional tone appropriate for the beauty industry."


def build_chinese_prompt(tagged_text: str, target_lang: str) -> str:
    """
    ì „ë¬¸ì ì¸ í•œêµ­ì–´â†’ì¤‘êµ­ì–´ ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ (ê°„ì²´/ë²ˆì²´ êµ¬ë¶„)
    """
    chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
    
    return (
        f"ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì¤‘êµ­ì–´({chinese_type})ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
        f"# ì£¼ìš” íŠ¹ì§•\n"
        f"- í”„ë ˆì  í…Œì´ì…˜, ë³´ê³ ì„œ, ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì„œ ë“±ì— ì í•©í•œ ê³µì‹ì ì´ê³  ì„¸ë ¨ëœ í‘œí˜„ ì‚¬ìš©\n"
        f"- ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ì™€ ë‰˜ì•™ìŠ¤ë¥¼ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í‘œí˜„ìœ¼ë¡œ ë²ˆì—­\n"
        f"- ì›ë¬¸ì˜ ì˜ë„ì™€ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë˜, ì¤‘êµ­ ì›ì–´ë¯¼ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ë¦¬ë„ë¡ ë¬¸ì¥ êµ¬ì¡° ì¡°ì •\n"
        f"- ë²ˆì—­ ì´ì™¸ì˜ ë¶ˆí•„ìš”í•œ ì„¤ëª… ê¸ˆì§€\n"
        f"- ì°½ì˜ì  ì¬í•´ì„ ì—†ì´ ì›ë¬¸ì— ì¶©ì‹¤í•œ ë²ˆì—­ ìˆ˜í–‰\n"
        f"- ë°˜ë“œì‹œ ì¤‘êµ­ì–´ {chinese_type}ë¡œ ë²ˆì—­í•˜ì„¸ìš”\n\n"
        f"# ê³ ìœ ëª…ì‚¬ ì²˜ë¦¬ ê·œì¹™\n"
        f"- 'í”¼ë”ë¦°'ì€ 'PYDERIN'ìœ¼ë¡œ ë²ˆì—­í•˜ì„¸ìš” (ë¸Œëœë“œëª…ì´ë¯€ë¡œ ëŒ€ë¬¸ìë¡œ)\n"
        f"- ê¸°íƒ€ ê³ ìœ ëª…ì‚¬(ì¸ëª…, ì§€ëª…, íšŒì‚¬ëª…, ë¸Œëœë“œëª… ë“±)ëŠ” ë²ˆì—­í•˜ì§€ ë§ê³  ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”\n"
        f"- ì˜ì–´ ê³ ìœ ëª…ì‚¬ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”\n\n"
        f"ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì¤‘êµ­ì–´({chinese_type})ë¡œ ë²ˆì—­í•˜ì„¸ìš”.\n"
        f"ì¤‘ìš”: [[R1]]...[[/R1]] ê°™ì€ ë§ˆì»¤ íƒœê·¸ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ê±°ë‚˜ ì œê±°í•˜ì§€ ë§ˆì„¸ìš”. ì •í™•íˆ ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        f"ë²ˆì—­í•  í…ìŠ¤íŠ¸:\n{tagged_text}"
    )


def build_prompt(tagged_text: str, target_lang: str, tone: str) -> str:
    # Chinese translation uses specialized prompt
    if "Chinese" in target_lang:
        return build_chinese_prompt(tagged_text, target_lang)
    
    tone_text = build_tone_instructions(tone)
    return (
        f"Translate the following beauty industry presentation text into natural, professional {target_lang}. "
        f"Only return the translated text. If there is nothing to translate, return an empty string. "
        f"Context: {tone_text} "
        f"Avoid literal translationâ€”use expressions that sound natural for beauty marketing and professional skincare. "
        f"If the source is already in {target_lang}, lightly copyedit for clarity, consistency, and terminology. "
        f"CRITICAL: Do NOT alter or remove any marker tags like [[R1]]...[[/R1]]. Keep them exactly as-is and in correct pairs. "
        f"Return the translated text with all markers preserved:\n\n{tagged_text}"
    )


# ---------- [ë²ˆì—­ í˜¸ì¶œ] ----------
def gpt_translate_tagged(tagged_text: str, client, target_lang: str, tone: str, use_deepseek=False) -> str:
    # ì§„ì§œ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ë²ˆì—­ ìŠ¤í‚µ
    if not tagged_text.strip() or is_effectively_empty_tagged(tagged_text):
        return ""

    # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° DeepSeek ì‚¬ìš©
    if "Chinese" in target_lang and use_deepseek:
        deepseek_client = create_deepseek_client(client.api_key)
        prompt = build_chinese_prompt(tagged_text, target_lang)
        content = safe_request(deepseek_client, prompt, retries=3, delay=3, use_deepseek=True)
    else:
        prompt = build_prompt(tagged_text, target_lang, tone)
        content = safe_request(client, prompt, retries=3, delay=3)

    # ì‹¤íŒ¨ ì‹œ ì›ë¬¸(ë§ˆì»¤ í¬í•¨) ë°˜í™˜ â†’ ì›ë¬¸ ìœ ì§€
    if not content:
        return tagged_text

    # ì‚¬ê³¼ë¬¸/ì—ëŸ¬ë¬¸êµ¬ê°€ ë“¤ì–´ì˜¤ë©´ ì›ë¬¸ ìœ ì§€
    if looks_like_apology(content):
        return tagged_text

    return content


def translate_presentation(pptx_path: str, target_lang: str, tone: str, openai_api_key: str, deepseek_api_key: str, use_deepseek=False, progress_callback=None):
    """
    í”„ë ˆì  í…Œì´ì…˜ì„ ë²ˆì—­í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    progress_callback: (current_slide, total_slides, current_text) -> None
    """
    print(f"ğŸ“‚ íŒŒì¼: {pptx_path}")
    print(f"ğŸŒ ëŒ€ìƒ ì–¸ì–´: {target_lang}")
    print(f"ğŸ™ í†¤: {tone}")
    if target_lang == "Chinese" and use_deepseek:
        print("ğŸ¤– DeepSeek ëª¨ë¸ ì‚¬ìš© ì¤‘...")
    else:
        print("ğŸ”‘ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")

    client = create_openai_client(openai_api_key)

    print("ğŸ“– í”„ë ˆì  í…Œì´ì…˜ ë¡œë”©...")
    pres = Presentation(pptx_path)

    slide_count = len(pres.slides)
    print(f"ğŸ–¼ ìŠ¬ë¼ì´ë“œ ìˆ˜: {slide_count}")
    
    # ì›ë³¸ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°±ì—… (ì¤‘êµ­ì–´ ë²ˆì—­ìš©)
    original_korean_backup = {}
    if "Chinese" in target_lang:
        chinese_type = "ê°„ì²´" if "Simplified" in target_lang else "ë²ˆì²´"
        print(f"ğŸ“ ì›ë³¸ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë°±ì—… ì¤‘... (ì¤‘êµ­ì–´ {chinese_type} ë²ˆì—­ìš©)")
        for s_idx, slide in enumerate(pres.slides, start=1):
            original_korean_backup[s_idx] = {}
            for shape_idx, shape in enumerate(slide.shapes):
                if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
                    tf = shape.text_frame
                    for p_idx, p in enumerate(tf.paragraphs):
                        tagged, _ = tag_paragraph(p)
                        if tagged:
                            original_korean_backup[s_idx][f"{shape_idx}_{p_idx}"] = tagged
                elif getattr(shape, "has_table", False) and shape.has_table:
                    for row_idx, row in enumerate(shape.table.rows):
                        for cell_idx, cell in enumerate(row.cells):
                            if not getattr(cell, "text_frame", None):
                                continue
                            tf = cell.text_frame
                            for p_idx, p in enumerate(tf.paragraphs):
                                tagged, _ = tag_paragraph(p)
                                if tagged:
                                    original_korean_backup[s_idx][f"table_{row_idx}_{cell_idx}_{p_idx}"] = tagged
    
    print("-" * 60)

    for s_idx, slide in enumerate(pres.slides, start=1):
        print(f"â–¶ ìŠ¬ë¼ì´ë“œ {s_idx}/{slide_count}")
        if progress_callback:
            progress_callback(s_idx, slide_count, f"ìŠ¬ë¼ì´ë“œ {s_idx} ì²˜ë¦¬ ì¤‘...")

        for shape_idx, shape in enumerate(slide.shapes):
            # í…ìŠ¤íŠ¸ í”„ë ˆì„
            if getattr(shape, "has_text_frame", False) and shape.has_text_frame:
                tf = shape.text_frame
                for p_idx, p in enumerate(tf.paragraphs):
                    tagged, style_map = tag_paragraph(p)
                    if not tagged:
                        continue
                    preview = (tagged[:40] + "...") if len(tagged) > 40 else tagged
                    print(f"   ğŸ”¤ ë²ˆì—­ ì¤‘(ì„œì‹ë³´ì¡´): {preview}")
                    if progress_callback:
                        progress_callback(s_idx, slide_count, f"í…ìŠ¤íŠ¸ ë²ˆì—­ ì¤‘: {preview}")
                    
                    translated = gpt_translate_tagged(tagged, client, target_lang, tone, use_deepseek)
                    translated = translated.strip().strip('"').strip("'")
                    
                    if not try_inplace_update_paragraph(p, translated):
                      # 2ï¸âƒ£ ì‹¤íŒ¨í•˜ë©´ rebuild ë°©ì‹ìœ¼ë¡œ fallback
                       rebuild_paragraph_from_tagged(p, translated, style_map)
                    
                    time.sleep(SLEEP_SEC)

            # í‘œ(ì…€ ë‚´ë¶€ë„ paragraph ë‹¨ìœ„ë¡œ ì²˜ë¦¬)
            elif getattr(shape, "has_table", False) and shape.has_table:
                for row_idx, row in enumerate(shape.table.rows):
                    for cell_idx, cell in enumerate(row.cells):
                        if not getattr(cell, "text_frame", None):
                            continue
                        tf = cell.text_frame
                        for p_idx, p in enumerate(tf.paragraphs):
                            tagged, style_map = tag_paragraph(p)
                            if not tagged:
                                continue
                            translated = gpt_translate_tagged(tagged, client, target_lang, tone, use_deepseek)
                            translated = translated.strip().strip('"').strip("'")
                            
                            if not try_inplace_update_paragraph(p, translated):
                                rebuild_paragraph_from_tagged(p, translated, style_map)
                            time.sleep(SLEEP_SEC)

    folder = os.path.dirname(pptx_path)
    stem, ext = os.path.splitext(os.path.basename(pptx_path))
    
    # ì¤‘êµ­ì–´ ë²ˆì—­ì˜ ê²½ìš° í†¤ ëŒ€ì‹  ì¤‘êµ­ì–´ íƒ€ì…ì„ ì‚¬ìš©
    if "Chinese" in target_lang:
        chinese_type = "Simplified" if "Simplified" in target_lang else "Traditional"
        outfile_name = f"{stem}_Chinese_{chinese_type}_AIë²ˆì—­ì™„ë£Œ{ext}"
    else:
        safe_tone = re.sub(r'[^0-9A-Za-zê°€-í£_()+-]', '', tone.replace(' ', ''))
        outfile_name = f"{stem}_{target_lang}_{safe_tone}_AIë²ˆì—­ì™„ë£Œ{ext}"
    
    outfile_path = os.path.join(folder, outfile_name)
    outfile_path = unique_path(outfile_path)

    print("-" * 60)
    print("ğŸ’¾ ì €ì¥ ì¤‘...")
    pres.save(outfile_path)
    print(f"âœ… ë²ˆì—­ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {outfile_path}")
    
    return outfile_path
